import os
from dotenv import load_dotenv
import google.generativeai as genai
import json

load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
model = None

# --- CONFIGURACION ---
if api_key:
    try:
        genai.configure(api_key=api_key)
        # Usamos tu modelo disponible
        model = genai.GenerativeModel("gemini-2.5-flash")
        print("‚úÖ IA CONECTADA: Backend listo con Gemini 2.5 Flash")
    except Exception as e:
        print(f"‚ùå Error configuraci√≥n IA: {e}")
else:
    print("‚ö†Ô∏è ADVERTENCIA: No se encontr√≥ GOOGLE_API_KEY en .env")

# --- PROTOCOLO (RAG MEJORADO Y HUMANIZADO) ---
PROTOCOLO_SEGURIDAD = """
ERES 'SAY IT', UN ASISTENTE VIRTUAL DE CONVIVENCIA ESCOLAR.
TU TONO: Calmado, seguro, confidencial y profesional.

REGLAS DE INTERACCI√ìN:

1. FASE DE SALUDO (IMPORTANTE):
   - Si el usuario dice "Hola", "Buenas", o saluda simple: NO asumas inmediatamente que ha pasado algo grave.
   - Respuesta correcta: "Hola. Estoy aqu√≠ para escucharte de forma segura y confidencial. ¬øQuieres contarme algo o necesitas ayuda?"
   - Respuesta INCORRECTA: "Siento que est√©s mal" (No lo digas si no sabes qu√© pasa).

2. FASE DE ESCUCHA (Cuando cuenten el problema):
   - Ahora S√ç muestra empat√≠a: "Siento mucho que est√©s pasando por eso."
   - Tu objetivo es conseguir 3 datos clave sin parecer un interrogatorio policial:
     A) QU√â (Descripci√≥n de los hechos).
     B) QUI√âN (Nombres o descripci√≥n de los agresores).
     C) CU√ÅNDO/D√ìNDE (Fecha y lugar).

3. FASE DE CIERRE:
   - Si tienes los datos o el alumno no quiere hablar m√°s, recu√©rdale que puede usar el bot√≥n "Generar Reporte" para enviar la informaci√≥n a direcci√≥n.

EJEMPLO DE FLUJO IDEAL:
- Usuario: "Hola"
- T√∫: "Hola. Aqu√≠ puedes hablar con confianza. ¬øC√≥mo puedo ayudarte?"
- Usuario: "Es que se meten conmigo"
- T√∫: "Lo siento mucho, nadie deber√≠a pasar por eso. ¬øPuedes decirme qui√©n te est√° molestando?"
"""

def responder_alumno(historial, mensaje_usuario):
    if not model:
        return "‚ö†Ô∏è Error: IA no conectada."

    try:
        historial_texto = ""
        for item in historial:
            if isinstance(item, (list, tuple)) and len(item) >= 2:
                human = item[0]
                ai = item[1]
                if human and ai:
                    historial_texto += f"Alumno: {human}\nSay It: {ai}\n"

        prompt_completo = f"""
        {PROTOCOLO_SEGURIDAD}
        
        HISTORIAL PREVIO:
        {historial_texto}
        
        NUEVO MENSAJE DEL ALUMNO:
        {mensaje_usuario}
        
        TU RESPUESTA (Directa y orientada a conseguir los datos):
        """
        
        response = model.generate_content(prompt_completo)
        return response.text
        
    except Exception as e:
        print(f"üî• ERROR CHAT: {e}")
        return "Disculpa, he tenido un fallo t√©cnico. ¬øPuedes repetirlo?"

def generar_reporte_riesgo(historial_chat):
    if not model:
        raise ConnectionError("Sin API Key")

    chat_str = str(historial_chat)
    prompt_analisis = f"""
    Act√∫a como analista. Extrae JSON puro de este chat:
    {chat_str}
    
    JSON ESPERADO:
    {{
        "rol_informante": "V√çCTIMA" o "TESTIGO",
        "tipo_incidente": ["F√≠sico", "Verbal", "Ciber"],
        "nivel_gravedad": "LEVE", "MODERADO" o "GRAVE",
        "resumen_hechos": "Resumen en 3 persona (max 30 palabras)",
        "nombres_involucrados": ["Nombres o Desconocido"]
    }}
    """
    
    response = model.generate_content(prompt_analisis)
    texto_limpio = response.text.replace("```json", "").replace("```", 
"").strip()
    return json.loads(texto_limpio)
